# 本章节为爬虫知识的复习，并且对其进行更为细致的讲解和扩充。
## 01 开发者工具和 `Fiddler` 工具介绍
### 相关介绍：主要讲解网络爬虫的相关网页知识，以及浏览器的开发者工具和专业的抓包软件 Fiddler 工具的使用。
### 一般情况下，使用 Chrome 浏览器的开发者工具即可解决。
## 02 `urllib` 库的介绍
### 相关介绍：
### 1.`important urllib.requeset` `reaponse` 相关知识介绍。
### 2.写入文件： ```with open() as fp:``` 相关介绍。
## 03 `parse` 的使用
### 相关介绍：主要讲解了 parse 的用法和相关的定义，并且使用拼接作用实践
#### 目标网址：http://www.baidu.com/ 
## 04 `get` 请求
## 相关介绍：
### 1.输入国家的名字
    word = input('请输入国家的名字：')
### 2.将参数写成一个字典。
### 3.发送请求，然后将返回的参数写入 HTML 文件中即可。
## 05 构建请求头部信息
### 相关介绍：如果只是简单的构建请求的对象，然后对其发起请求，最后输出的话，会看到传送的网页信息不全面，所以使用 `headers` 与 `cookie` 进行伪装浏览器。
        headers = {
            'User-Agent': ''
            'cookie':''
        }
#### 目标网址：http://www.baidu.com/
## 06 post请求
## 相关介绍：之前介绍过 `get` 请求方式，这里主要介绍一下 `post` 的请求方式。
### 1.post请求讲解：阿贾克斯请求
### 看 XHR 里面请求头里面有 `X-Requested-With` 的话就是 `post` 请求。
### 2.构建表单数据，写成一个字典，对字典就行发送请求即可。
        from_data = {
            'kw': word,
        }
### 3.百度翻译 搜索baby
### 找到 `XHR` 即可 发现第四个 sug 是目标的网址，使用 www.json.cn 网址进行 `json` 格式的转换，发现可以进行json格式的转换。
#### 目标网址：https://fanyi.baidu.com/?aldtype=16047#auto/zh 
